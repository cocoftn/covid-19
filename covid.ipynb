{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# COVID-19 Open Research Dataset Challenge (CORD-19) - Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge?fbclid=IwAR1kPwO-OjU-MGEYnaaDAIHVfJ5lyhpn3V79AnL20bE1IOb16pmEg5H1NMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In response to the COVID-19 pandemic, the White House and a coalition of leading research groups have prepared the COVID-19 Open Research Dataset (CORD-19). CORD-19 is a resource of over 47,000 scholarly articles, including over 36,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses. This freely available dataset is provided to the global research community to apply recent advances in natural language processing and other AI techniques to generate new insights in support of the ongoing fight against this infectious disease. There is a growing urgency for these approaches because of the rapid acceleration in new coronavirus literature, making it difficult for the medical research community to keep up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are issuing a call to action to the world's artificial intelligence experts to develop text and data mining tools that can help the medical community develop answers to high priority scientific questions. The CORD-19 dataset represents the most extensive machine-readable coronavirus literature collection available for data mining to date. This allows the worldwide AI research community the opportunity to apply text and data mining approaches to find answers to questions within, and connect insights across, this content in support of the ongoing COVID-19 response efforts worldwide. There is a growing urgency for these approaches because of the rapid increase in coronavirus literature, making it difficult for the medical community to keep up.\n",
    "\n",
    "A list of our initial key questions can be found under the Tasks section () of this dataset. These key scientific questions are drawn from the NASEM’s SCIED (National Academies of Sciences, Engineering, and Medicine’s Standing Committee on Emerging Infectious Diseases and 21st Century Health Threats) research topics and the World Health Organization’s R&D Blueprint for COVID-19.\n",
    "\n",
    "Many of these questions are suitable for text mining, and we encourage researchers to develop text mining tools to provide insights on these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Details** What is known about transmission, incubation, and environmental stability? What do we know about natural history, transmission, and diagnostics for the virus? What have we learned about infection prevention and control?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, we want to know what the literature reports about:\n",
    "\n",
    "1. Range of incubation periods for the disease in humans (and how this varies across age and health status) and how long individuals are contagious, even after recovery.\n",
    "2. Prevalence of asymptomatic shedding and transmission (e.g., particularly children).\n",
    "3. Seasonality of transmission.\n",
    "4. Physical science of the coronavirus (e.g., charge distribution, adhesion to hydrophilic/phobic surfaces, environmental survival to inform decontamination efforts for affected areas and provide information about viral shedding).\n",
    "5. Persistence and stability on a multitude of substrates and sources (e.g., nasal discharge, sputum, urine, fecal matter, blood).\n",
    "6. Persistence of virus on surfaces of different materials (e,g., copper, stainless steel, plastic).\n",
    "7. Natural history of the virus and shedding of it from an infected person\n",
    "8. Implementation of diagnostics and products to improve clinical processes\n",
    "9. Disease models, including animal models for infection, disease and transmission\n",
    "10. Tools and studies to monitor phenotypic change and potential adaptation of the virus\n",
    "11. Immune response and immunity\n",
    "12. Effectiveness of movement control strategies to prevent secondary transmission in health care and community settings\n",
    "13. Effectiveness of personal protective equipment (PPE) and its usefulness to reduce risk of transmission in health care and community settings\n",
    "14. Role of the environment in transmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to respond to this Call to Action, and provide answers to these questions, i implemented an information retrieval engine, based on both Latent Dirichlet Allocation model (Blei et Al, 2003, for topics modelling, and Query likelihood maximum model for information retrieval. This model is called LDA-Based Document Models, and was theorised and experimented in 2006 by Xing Wei and W. Bruce Croft from the Computer Science Department of University of Massachusetts Amherst.\n",
    "The tool is basically a simple search engine, it was designed to allow the user to query the given dataset to find the most relevants research papers.\n",
    "\n",
    "Different researches in the machine learning litterature showed that documents clustering can improve retrieval effectiveness in the language modeling framework (Hoffman, 1999, probabilistic Latent Semantic Indexing (pLSI), Liu and Croft,2004, Cluster-Based Model). The experiments carried out by Liu and Croft showed that lda-based model (LBDM) outperforms both query likelihood model and cluster-based retrieval model (CBDM).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"./img/results.png\" width=\"500\" height=\"335\"/>\n",
    "<figcaption>Comparison of query likelihood retrieval (QL), cluster-based retrieval (CBDM) and retrieval with the LDA- based document models (LBDM). The evaluation measure is average precision. AP data set. Stars indicate statistically significant differences in performance with a 95% confidence according to the Wilcoxon test.\n",
    "Table taken from LDA-Based Document Models for Ad-hoc Retrieval</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunatally, the given dataset does not include a query sets with its relevants documents to appreciate correctly the effectiveness of my model measuring the precision and the recall. However, i could still have an idea of the effectivness of the LDA-based model, directly by looking at the content of retrieves documents from any query. Furthermore, due te its limited capacities, my laptop was not able to processed the whole dataset.\n",
    "\n",
    "Finally, the lda-based model has proved to be very efficient for quickly retrieving relevant informations from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA-based model is a great tool for retrieving most relevant articles, but it do not directly answer to the question. For that we have to go deeper in the text mining, in order to extract insight from the most relevant articles retrieved by the algorithm. in that respect, our LDA-based could be a good starting point.\n",
    "\n",
    "To get the model more handly, it could be possible to develop a graphic interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ressources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is all the ressources that help me implement the model\n",
    "- Xing Wei and W. Bruce Croft, \"LDA-Based Document Models for Ad-hoc Retrieval\", 2006\n",
    "- 2009 Cambridge University, 8 Evaluation in information retrieval p. 151-175 link : https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf\n",
    "- Youtube, PyData, Bhargav Srinivasa Desikan - Topic Modelling (and more) with NLP framework Gensim. Link : https://www.youtube.com/watch?v=ZkAFJwi-G98&list=PLdgx9krQrE0Ng5c80ko5TEZESGtQ9qGM3&index=6&t=214s\n",
    "- GenSim documentation : https://radimrehurek.com/gensim/auto_examples/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "from numpy import save\n",
    "\n",
    "# Gensim library\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.matutils import corpus2csc\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#gc.collect()\n",
    "#reset_selective -f test_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "#!pip install google-compute-engine\n",
    "#!pip3 uninstall boto\n",
    "#!pip install --upgrade gensim smart_open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the limited ressources of my laptop, i could not handle the whole dataset, so i selected only the best papers, those that fulfill the condition has_full_text=True, and i removed papers without any title and/or no abstracts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv('./CORD-19-research-challenge/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_full_text = meta[meta.has_full_text == True]\n",
    "#meta_full_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#body-text or abstracts\n",
    "def get_content(tag_content):\n",
    "    content = ''\n",
    "    c = 1\n",
    "    for el in tag_content:\n",
    "        content += el['text'] + ' '\n",
    "        c += 1\n",
    "        \n",
    "    return content\n",
    "#TO - DO\n",
    "#def get_ref(bibref_content):\n",
    "#    bib_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "publish_time = []\n",
    "paper_id = []\n",
    "titles = []\n",
    "abstracts = []\n",
    "bodies = []\n",
    "authors_name = []\n",
    "for sha in meta_full_text['sha']:\n",
    "    #because sha can contain more than 1 sha, so we split the sha into array \n",
    "    for sha2 in [x.strip() for x in sha.split(sep=';')]:\n",
    "        file = './papers/' + sha2 + '.json'\n",
    "        with open(file) as f:\n",
    "            json_data = json.load(f)\n",
    "        paper_id.append(sha2)\n",
    "        titles.append(meta_full_text[meta_full_text.sha == sha]['title'].iloc[0])\n",
    "        publish_time.append(meta_full_text[meta_full_text.sha == sha]['publish_time'].iloc[0])\n",
    "        abstracts.append(get_content(json_data['abstract']))\n",
    "        bodies.append(get_content(json_data['body_text']))\n",
    "\n",
    "\n",
    "d = {\n",
    "    'paper_id':paper_id,\n",
    "    'title':titles,\n",
    "    'abstract': abstracts,\n",
    "    'body' : bodies}\n",
    "\n",
    "\n",
    "docs = pd.DataFrame(d)\n",
    "\n",
    "\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "docs.to_csv(\"dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_docs = pd.read_csv(\"dataset.csv\")\n",
    "print(df_docs.shape)\n",
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In text pre-processing, we exclude punctuation and stop words (such as, \"if\", \"the\", or \"on\", which contain little topical content), stem and lemmatize all text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets Merge all three columns (title abstract and body) into one column content_word, after dropping Nan Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_papers = pd.read_csv('dataset.csv')\n",
    "#drop NaN value\n",
    "print('shape : ' + str(df_papers.shape))\n",
    "df_papers_dropna = df_papers.dropna()\n",
    "print('shape (after drop nan) : ' + str(df_papers_dropna.shape))\n",
    "df_papers_dropna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_papers_dropna['content_word'] = df_papers_dropna[df_papers_dropna.columns[1:]].apply(\n",
    "    lambda x: ' '.join(x.astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "df_papers_merged = df_papers_dropna[['paper_id','content_word']]\n",
    "df_papers_merged.shape\n",
    "df_papers_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming Lemmatization and Tokenizing using nlkt library"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#download corpora/stopwords and model/punkt\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize a list of stop words wish does not figure in the original NLKT stopwords list\n",
    "stop_words_list = ['%', '0', '1', '2', '3', '4', '5', '<', '=', '>', 'also', 'although',\n",
    "                   'and/or', 'b', 'c', 'conclude', 'conclusion', 'could', 'either', 'first',\n",
    "                   'follow', 'followed', 'following', 'furthermore', 'h', 'however', 'ii', 'last',\n",
    "                   'later', 'less', 'make', 'may', 'might', 'moreover', 'much', 'need', 'new',\n",
    "                   'often', 'one', 'rather', 'result', 'result', 'results', 'see', 'seen', 'set',\n",
    "                   'still', 'studied', 'studies10', 'study', 'therefore', 'thus', 'together', 'two',\n",
    "                   'us', 'use', 'use', 'way', 'well', 'whereas', 'whether', 'within', 'without', \n",
    "                   'would', 'year', 'yet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#obtain the resource :\n",
    "#nltk.download()\n",
    "import re\n",
    "#!pip install --user -U nltk\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#from nltk.stem import PorterStemmer\n",
    "#from nltk.stem import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "snowball = SnowballStemmer(\"english\",ignore_stopwords = True)\n",
    "def stemSentence(sentence):\n",
    "    sentence = re.sub(\"[?:!|.`',;()*-+]\", \"\", sentence)\n",
    "    sentence = sentence.replace(\"[\",\"\")\n",
    "    sentence = sentence.replace(\"]\",\"\")\n",
    "    sentence = sentence.lower()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    stop_words.update(stop_words_list)\n",
    "    token_words=word_tokenize(sentence)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        if word not in stop_words:\n",
    "            stem_sentence.append(snowball.stem(word))\n",
    "    return stem_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stemDataSet\n",
    "#parameter : two columns dataframe : paper_id and content words\n",
    "#return a stemmed and lemmatized matrix, in a numpy\n",
    "def stemDataSet(original_dataframe):\n",
    "    stemmed_words = []\n",
    "    for s_brut in original_dataframe['content_word']:\n",
    "        stemmed_words.append(stemSentence(s_brut))\n",
    "    return np.array([original_dataframe['paper_id'],stemmed_words]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceed to the Stemming and tokenization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_processed_numpy = stemDataSet(df_papers_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the newly created processed dataset.\n",
    "save('dataset_processed_2.npy',dataset_processed_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Latent Dirichlet Allocation using GENSIM framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21260, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load numpy array from npy file\n",
    "papers_matrix = load('dataset_processed.npy',allow_pickle=True )\n",
    "papers_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mapping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# return the original paper's identifiant from id in the corpus\n",
    "def id2paper(doc_id):\n",
    "    return papers_matrix[doc_id][0]\n",
    "\n",
    "# return id in the corpus from the original identifiant\n",
    "def paper2id(paper_id):\n",
    "    return np.argwhere(papers_matrix[:,0] ==paper_id)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting text to bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dictionary encapsulates the mapping between normalized words and their integer ids.\n",
    "dictionary = Dictionary(papers_matrix[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in papers_matrix[:,1]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Collection frequencies: token_id -> how many instances of this token are contained in the documents.\n",
    "{dictionary[k]: v for k, v in sorted(dictionary.cfs.items(), key=lambda item: item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Document frequencies: token_id -> how many documents contain this token.\n",
    "{dictionary.id2token[k]: v for k, v in sorted(dictionary.dfs.items(), key=lambda item: item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to https://radimrehurek.com/gensim/models/ldamulticore.html,\n",
    "number of workers should be one less than the number of core, we have a dual-core, so we set the parameter workers to 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the experiment of Wei Bruce Croft experiment : After 50 iterations, performance is quite stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use symmetric Dirichlet priors in the LDA estimation with α = 50 / K and η=0.01, which are common settings in the\n",
    "literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#initialize number of topics k = [0,k-1]\n",
    "lda_model.clear()\n",
    "k = 200\n",
    "alpha = 50/k\n",
    "eta = 0.01\n",
    "lda_model =  LdaMulticore(\n",
    "                        corpus=bow_corpus, \n",
    "                        num_topics = k,\n",
    "                        iterations = 50,\n",
    "                        alpha=alpha,\n",
    "                        eta=eta,\n",
    "                        id2word = dictionary,                                    \n",
    "                        workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save model to disk.\n",
    "temp_file = datapath(\"lda_model_k250\")\n",
    "lda_model.save(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a potentially pretrained model from disk.\n",
    "temp_file = datapath(\"lda_model_k100\")\n",
    "lda_model = LdaMulticore.load(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Initialize important matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our LDA model we construct the document θ theta and φ phi matrix, respectively the documents distribution over topics and the topics distribution over words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Phi - φ\n",
    "# get_topics : Get the term-topic matrix learned during inference.\n",
    "word_topic_matrix = lda_model.get_topics()\n",
    "\n",
    "# Theta - θ\n",
    "# get_document_topics() : Get the topic distribution for the given document.\n",
    "documents_topics = lda_model.get_document_topics(bow_corpus, minimum_probability=0)\n",
    "all_topics_csr = corpus2csc(documents_topics)\n",
    "doc_topics_matrix = all_topics_csr.T.toarray()\n",
    "\n",
    "# Save numpy matrix to disk\n",
    "save('word_topic_matrix_k300.npy',word_topic_matrix)\n",
    "save('doc_topics_matrix_k300.npy',doc_topics_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load numpy matrix θ and φ from npy file\n",
    "word_topic_matrix = load('word_topic_matrix.npy',allow_pickle=True )\n",
    "doc_topics_matrix   = load('doc_topics_matrix.npy',allow_pickle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# After we get the posterior estimates of θ and φ , \n",
    "# we can compute the probability of a word in a document as following,\n",
    "def proba_of_word_in_doc_lda(word_id,doc_id):\n",
    "    return np.sum(word_topic_matrix[:,word_id]*doc_topics_matrix[doc_id,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function proba_of_word_in_doc_lda above correspond to the following posterior probability :\n",
    "$P_{lda}( w | d,\\hat{\\theta},\\hat{\\phi}) = \\sum_{z=1}^{K}P(w|z,\\hat{\\phi})P(z|\\hat{\\theta},d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query likelihood model for IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the words frequency for the ML model. A dok matrix is necessary to retrieve quikly the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import dok_matrix\n",
    "words_frequence_matrix = dok_matrix((papers_matrix.shape[0], len(dictionary)), dtype=int)\n",
    "for i in range(papers_matrix.shape[0]):\n",
    "    for tupl in bow_corpus[i]:\n",
    "        words_frequence_matrix[i,tupl[0]] = tupl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62223933"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GLOBAL\n",
    "# Number of tokens in documents\n",
    "NB_WORDS = 0\n",
    "for doc in papers_matrix:\n",
    "    NB_WORDS += len(doc[1])\n",
    "NB_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# return the total number of token in the given document\n",
    "def get_nb_token(doc_id):\n",
    "    return len(papers_matrix[doc_id][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sys.getsizeof(words_frequence_matrix)/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def proba_of_word_in_doc_ml(word_id,doc_id):\n",
    "    # μ (mu) smooting prior : a small value of mu means more smoothing, we use a fix value of μ = 1000,\n",
    "    # since the best results are consistently obtained with this setting (according to the reported experiments\n",
    "    # of Liu and Croft.\n",
    "    # Nd is the number of token in the document D\n",
    "    mu = 1000\n",
    "    Nd = get_nb_token(doc_id)\n",
    "    # we compute the maximum likelihood of P(w|Md) and P(w|Mc)\n",
    "    p_w_given_md = words_frequence_matrix[doc_id,word_id]/Nd\n",
    "    p_w_given_mc = dictionary.cfs[word_id]/NB_WORDS\n",
    "    return (Nd/(Nd+mu))*p_w_given_md*(1 - Nd/(Nd+mu))*p_w_given_mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proba_of_word_in_doc_ml(word_id,doc_id) correspond to the following the probability :\n",
    "\n",
    "$P(w|D)= \\frac{Nd}{Nd +μ}P_{ML} (w|D)+(1−\\frac{Nd}{Nd +μ})P_{ML}(w|coll)$\n",
    "\n",
    "where P’(w|D) is the maximum likelihood estimate of word w in the document D, and P’(w|coll) is the maximum likelihood estimate of word w in the entire collection. μ is the Dirichlet\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import timeit\n",
    "#timeit.timeit('proba_of_word_in_doc_ml(1,8)', number=20000,globals=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval with LDA + Query likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is the function that linearly combine document model and LDA\n",
    "# parameter : word_id, doc_id\n",
    "# return : the probability of the of the word_id given doc_id\n",
    "#lm_score_words_docs = [] # contain lm score for each words\n",
    "#lda_score_words_docs = [] # contain lda score for each words\n",
    "def word_score_lbdm(word_id, doc_id):\n",
    "    #the parameter lmbda secify the proportion of LDA in the linear combination\n",
    "    lmbda = 0.9\n",
    "    #lm_score_words_docs.append([doc_id,proba_of_word_in_doc_ml(word_id,doc_id)])\n",
    "    #lda_score_words_docs.append([doc_id,proba_of_word_in_doc_lda(word_id,doc_id)])\n",
    "    return lmbda*proba_of_word_in_doc_ml(word_id,doc_id)+(1-lmbda)*proba_of_word_in_doc_lda(word_id,doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timeit.timeit('word_score_lbdm(85524,4)', number=22000*4,globals=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The function tokenize and stem the given query, and compute the score of each word in the given document\n",
    "# parameter: the query string, the document id\n",
    "# return the score of the query in the document id\n",
    "#lbdm_score_words_docs = [] # contain lbdm score for each words\n",
    "def query_score_lbdm(query,doc_id):\n",
    "    score = 1\n",
    "    #lbdm_score_words = []\n",
    "    for term in query:\n",
    "        term_score = word_score_lbdm(term,doc_id)  \n",
    "        #lbdm_score_words.append(term_score)\n",
    "        score *= term_score\n",
    "    #lbdm_score_words_docs.append([doc_id,lbdm_score_words])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeit.timeit('query_score_lbdm(test_q,3)', number=22000,globals=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function that wrap up all the aboves function\n",
    "# parameter : (raw) query\n",
    "# return : the ranked list of the most 10 relevant paper id, with its rank score\n",
    "def run_search_query(q): \n",
    "    # convert string query to a list of token id\n",
    "    stem_query = [dictionary.token2id[term] for term in stemSentence(q) if dictionary.token2id.get(term)]\n",
    "    docs_score_vector = []\n",
    "    for i in range(papers_matrix.shape[0]):\n",
    "        docs_score_vector.append([i,query_score_lbdm(stem_query,i)])\n",
    "        #if(i%5000 == 0): print(i)\n",
    "    docs_score_vector.sort(key=lambda x: x[1], reverse= True)\n",
    "\n",
    "    return docs_score_vector[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluatethe effectivness, we have two solutions : we judge by ourself if the document retrieved are relevant according to the input query.\n",
    "Or in a more scientific way, we sample a set of query from papers title, execute all the queries in the sample and compute the number of time that the assiocated document is present in the top ten documents retrieved. With this method, we find a precision very close to the mean precision from the orignial experiment (see table at the beginning)\n",
    "with the parameters :\n",
    "λ = 0,7\n",
    "Precision is 0,255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a sample from the dataset of paper we want to test\n",
    "import random as rd\n",
    "df_docs = pd.read_csv(\"dataset.csv\")\n",
    "sample = rd.seed(30)\n",
    "sample = rd.sample(range(0, len(papers_matrix)), 200)\n",
    "paper_title = []\n",
    "for s in sample:\n",
    "    s_ = id2paper(s)\n",
    "    ti = df_docs[df_docs.paper_id == s_]['title'].iloc[0]\n",
    "    paper_title.append([s_,ti])\n",
    "    \n",
    "%reset_selective -f df_docs\n",
    "print(\"gc collect : \" + str(gc.collect()))\n",
    "print(len(paper_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_position = []\n",
    "for i in range(0,200):\n",
    "    p_id = paper2id(paper_title[i][0])\n",
    "    #print('paper id : ' + paper_title[i][0] + \" / \" + str(p_id))\n",
    "    un_titre = paper_title[i][1]\n",
    "    res = run_search_query(un_titre)\n",
    "    pos = [doc_id[0] for doc_id in res].index(p_id)\n",
    "    list_position.append(pos)\n",
    "    print(str(i) + ' -- Position in the vector : ' + str(pos))\n",
    "    #print('Top 3 most relevant paper : ')\n",
    "    #print([id2paper(p[0]) for p in res[:3]])\n",
    "print('Completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print evaluation score :\n",
    "from statistics import mean\n",
    "top_ten = len([it for it in list_position if it < 10])/len(list_position)\n",
    "print(\"% in the top ten : \" + str(top_ten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### parameter-selecting experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Full term list.\n",
    "menu = [\"incubation period in humans COVID-19\",\n",
    "        \"COVID-19 contagious period\",\"COVID-19 asymptomatic shedding\",\n",
    "        \"asymptomatic transmission COVID-19\",\"seasonality coronavirus\",\n",
    "        \"charge distribution COVID-19\",\"hydrophilic surfaces COVID-19\",\n",
    "        \"hydrophobic surfaces\",\"environmental survival\",\n",
    "        \"decontamination\",\"viral shedding\",\n",
    "        \"persistence\",\"stability\",\"natural history\",\"diagnostics covid\",\n",
    "        \"clinical process\",\"disease model\",\"phenotypic change\",\n",
    "        \"immune response\",\"secondary transmission\",\n",
    "        \"personal protective equipment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a query among the list above, or type a query and affect it to the variable query and run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = menu[3]\n",
    "results = run_search_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the cell below to see the result. Result is contained into the pandas data frame \"df_res\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : Transmission potential of influenza A/H7N9, February to May 2013, China\n",
      " --- \n",
      "2 : Assessing the Impact of Reduced Travel on Exportation Dynamics of Novel Coronavirus Infection (COVID-19)\n",
      " --- \n",
      "3 : Feasibility of controlling COVID-19 outbreaks by isolation of cases and contacts\n",
      " --- \n",
      "4 : Feasibility of controlling COVID-19 outbreaks by isolation of cases and contacts\n",
      " --- \n",
      "5 : Time variations in the transmissibility of pandemic influenza in Prussia, Germany, from 1918–19\n",
      " --- \n",
      "6 : Effect of the One-Child Policy on Influenza Transmission in China: A Stochastic Transmission Model\n",
      " --- \n",
      "7 : The Waiting Time for Inter-Country Spread of Pandemic Influenza\n",
      " --- \n",
      "8 : Analysis of the epidemic growth of the early 2019-nCoV outbreak using internationally confirmed cases\n",
      " --- \n",
      "9 : Estimates of Outbreak Risk from New Introductions of Ebola with Immediate and Delayed Transmission Control\n",
      " --- \n",
      "10 : Estimating human-to-human transmissibility of hepatitis A virus in an outbreak at an elementary school in China, 2011\n",
      " --- \n",
      "11 : Predicting and Evaluating the Epidemic Trend of Ebola Virus Disease in the 2014-2015 Outbreak and the Effects of Intervention Measures\n",
      " --- \n",
      "12 : Early dynamics of transmission and control of COVID-19: a mathematical modelling study\n",
      " --- \n",
      "13 : Estimation of the Transmission Risk of the 2019-nCoV and Its Implication for Public Health Interventions\n",
      " --- \n",
      "14 : Containing the accidental laboratory escape of potential pandemic influenza viruses\n",
      " --- \n",
      "15 : Large-scale Lassa fever outbreaks in Nigeria: quantifying the association between disease reproduction number and local rainfall\n",
      " --- \n",
      "16 : Real-Time Estimation of the Risk of Death from Novel Coronavirus (COVID-19) Infection: Inference Using Exported Cases\n",
      " --- \n",
      "17 : Predicting the cumulative number of cases for the COVID-19 epidemic in China from early data\n",
      " --- \n",
      "18 : The Novel Coronavirus, 2019-nCoV, is Highly Contagious and More Infectious Than Initially Estimated\n",
      " --- \n",
      "19 : SEIR Transmission dynamics model of 2019 nCoV coronavirus with considering the weak infectious ability and changes in latency duration\n",
      " --- \n",
      "20 : Mechanisms for lyssavirus persistence in non-synanthropic bats in Europe: insights from a modeling study\n",
      " --- \n"
     ]
    }
   ],
   "source": [
    "#df_docs = pd.read_csv(\"dataset.csv\")\n",
    "relevant_list = []\n",
    "for p in [id2paper(x[0]) for x in results]:\n",
    "    relevant_list.append([\n",
    "    df_docs[df_docs.paper_id == p]['paper_id'],\n",
    "    df_docs[df_docs.paper_id == p]['title'],\n",
    "    df_docs[df_docs.paper_id == p]['abstract'],\n",
    "    df_docs[df_docs.paper_id == p]['body']])\n",
    "    \n",
    "df_res = pd.DataFrame(relevant_list, columns = ['paper_id','title','abstract','body'])\n",
    "for i in range(20):\n",
    "    print(str(i+1) + ' : ' + df_res['title'].iloc[i].iloc[0])\n",
    "    print(' --- ')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stem_query = stemSentence(query)\n",
    "word_found = []\n",
    "for p in [id2paper(x[0]) for x in results]:\n",
    "    wf = []\n",
    "    for t in stem_query:\n",
    "        wf.append(t in papers_matrix[papers_matrix[:,0]==p][0][1])\n",
    "    word_found.append(wf)\n",
    "print(stem_query)\n",
    "word_found           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
